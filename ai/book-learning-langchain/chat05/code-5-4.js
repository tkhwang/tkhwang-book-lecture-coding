import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { Annotation, END, messagesStateReducer, START, StateGraph } from '@langchain/langgraph';
import { ChatOpenAI } from '@langchain/openai';
import 'dotenv/config';

const modelLowTemp = new ChatOpenAI({
  model: 'gpt-4o-mini',
  temperature: 0.1,
  apiKey: process.env.OPENAI_API_KEY,
});

const modelHighTemp = new ChatOpenAI({
  model: 'gpt-4o-mini',
  temperature: 0.7,
  apiKey: process.env.OPENAI_API_KEY,
});

const annotation = Annotation.Root({
  messages: Annotation({
    reducer: messagesStateReducer,
    default: () => [],
  }),
  user_query: Annotation(),
  sql_query: Annotation(),
  sql_explanation: Annotation(),
});

const generatePrompt = new SystemMessage(
  'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±í•˜ì„¸ìš”.'
);

async function generateSql(state) {
  const userMessage = new HumanMessage(state.user_query);
  const messages = [generatePrompt, ...state.messages, userMessage];

  const response = await modelLowTemp.invoke(messages);
  return {
    sql_query: response.content,
    messages: [...messages, response],
  };
}

const explainPrompt = new SystemMessage(
  'ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ SQL ì¿¼ë¦¬ë¥¼ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.'
);

async function explainSql(state) {
  const messages = [explainPrompt, ...state.messages];
  const response = await modelHighTemp.invoke(messages);
  return {
    sql_explanation: response.content,
    messages: response,
  };
}

const workflow = new StateGraph(annotation)
  .addNode('generate_sql', generateSql)
  .addNode('explain_sql', explainSql)
  .addEdge(START, 'generate_sql')
  .addEdge('generate_sql', 'explain_sql')
  .addEdge('explain_sql', END);

const graph = workflow.compile();

const input = { user_query: 'ìµœê·¼ 30ì¼ ë™ì•ˆ ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆì€ ë¬´ì—‡ì¸ê°€ìš”?' };

const result = await graph.invoke(input);
console.log('ğŸš€ ~ result:', result);
